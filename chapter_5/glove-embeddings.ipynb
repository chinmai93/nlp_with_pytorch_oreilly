{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97a8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317b9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainedEmbeddings(object):\n",
    "    def __init__(self, word_to_index, word_vectors):\n",
    "        self.word_to_index = word_to_index\n",
    "        self.word_vectors = word_vectors\n",
    "        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n",
    "        self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n",
    "        for _, i in self.word_to_index.items():\n",
    "            self.index.add_item(i, self.word_vectors[i])\n",
    "        self.index.build(50)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_embeddings_file(cls, embedding_file):\n",
    "        word_to_index = {}\n",
    "        word_vectors = []\n",
    "        with open(embedding_file) as fp:\n",
    "            for line in fp.readlines():\n",
    "                line = line.split(\" \")\n",
    "                word = line[0]\n",
    "                vec = np.array([float(x) for x in line[1:]])\n",
    "                \n",
    "                word_to_index[word] = len(word_to_index)\n",
    "                word_vectors.append(vec)\n",
    "        return cls(word_to_index, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3366aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75f2f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21843    0.022696  -0.062105  -0.25557   -0.2222     0.75584\n",
      " -0.58643   -0.3236     0.0036797 -0.52816   -0.18682    0.16995\n",
      "  0.38306    0.26499   -0.081493  -0.85389    0.078729   0.55321\n",
      " -0.94035   -0.046033   0.25873   -0.51662    0.17764   -0.54664\n",
      " -0.64107   -0.71131   -0.66956   -0.16875    0.25056   -0.073421\n",
      "  0.742      0.21894   -0.60056   -0.66511    0.87591   -0.43214\n",
      " -0.16481    0.15383   -0.4014    -0.17786   -0.57662    0.038627\n",
      " -0.1438    -0.21172    0.023644  -0.38741   -0.091636   0.80288\n",
      " -0.56324   -0.7643    -0.15529    0.40837    0.023216   1.6483\n",
      " -0.36147   -1.8609     0.40398   -0.41986    1.5969     0.2239\n",
      " -0.26619    1.3771    -0.43608    0.1363     0.62087    0.33013\n",
      "  0.90322    0.22929   -0.072946  -0.16841   -0.13554    0.0075493\n",
      " -0.2734    -0.25576    0.061146  -0.13276   -0.21993   -0.29111\n",
      " -0.20789   -0.1394     0.20315    0.11451   -0.68641    0.63453\n",
      " -1.4408    -0.301     -0.42911    0.48833   -0.91329    0.037517\n",
      " -0.35243   -0.31124    0.39479   -0.48404   -0.58556   -0.57038\n",
      " -0.39338    0.26525    0.95566    0.084452 ] themselves\n"
     ]
    }
   ],
   "source": [
    "ind = 1000\n",
    "print(embeddings.word_vectors[ind], embeddings.index_to_word[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

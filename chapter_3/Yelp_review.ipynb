{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "010b8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a74c7",
   "metadata": {},
   "source": [
    "## Get Yelp Reviews Lite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6beb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = Namespace(\n",
    "    raw_train_dataset_csv=\"data/yelp/train.csv\",\n",
    "    raw_test_dataset_csv=\"data/yelp/test.csv\",\n",
    "    proportion_subset_of_train=0.1,\n",
    "    train_proportion=0.7,\n",
    "    val_proportion=0.15,\n",
    "    test_proportion=0.15,\n",
    "    output_munged_csv=\"data/yelp/reviews_with_splits_lite.csv\",\n",
    "    seed=1337\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa3c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0f55f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "train_reviews = pd.read_csv(args.raw_train_dataset_csv, header=None, names=['rating', 'review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b52a1a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>650000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.414215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating\n",
       "count  650000.000000\n",
       "mean        3.000000\n",
       "std         1.414215\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         4.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b8a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making the subset equal across the review classes\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in train_reviews.iterrows():\n",
    "    by_rating[row.rating].append(row.to_dict())\n",
    "    \n",
    "\n",
    "# create split data\n",
    "final_list = []\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "    np.random.shuffle(item_list)\n",
    "    \n",
    "    n_total = len(item_list)\n",
    "    n_subset = int(args.proportion_subset_of_train * n_total)\n",
    "    n_train = int(args.train_proportion * n_subset)\n",
    "    n_val = int(args.val_proportion * n_subset)\n",
    "    n_test = int(args.test_proportion * n_subset)\n",
    "    \n",
    "    # Give data point a split attribute\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "        \n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "        \n",
    "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
    "        item['split'] = 'test'\n",
    "    \n",
    "    ## Add to final list\n",
    "    final_list.extend(item_list[:n_train+n_val+n_test])\n",
    "\n",
    "final_reviews = pd.DataFrame(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4df5a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal clean\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c138de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reviews.review = final_reviews.review.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84f559a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the sushi was fine , but after last night s ex...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rude and obnoxious people work here ! i will n...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>stay away from olympic garden unless you are a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>horrible horrible experience . is selling pupp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>where do i start . . . if you are looking for ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64995</th>\n",
       "      <td>5</td>\n",
       "      <td>as good as it gets for the dennys ihave been t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64996</th>\n",
       "      <td>5</td>\n",
       "      <td>we enjoyed lillie s teppanyaki or as they call...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64997</th>\n",
       "      <td>5</td>\n",
       "      <td>we just purchased a vehicle from centennial la...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64998</th>\n",
       "      <td>5</td>\n",
       "      <td>they make great vegetarian thai food they do t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64999</th>\n",
       "      <td>5</td>\n",
       "      <td>it s a must to stop at trader joes while in ve...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                             review  split\n",
       "0           1  the sushi was fine , but after last night s ex...  train\n",
       "1           1  rude and obnoxious people work here ! i will n...  train\n",
       "2           1  stay away from olympic garden unless you are a...  train\n",
       "3           1  horrible horrible experience . is selling pupp...  train\n",
       "4           1  where do i start . . . if you are looking for ...  train\n",
       "...       ...                                                ...    ...\n",
       "64995       5  as good as it gets for the dennys ihave been t...   test\n",
       "64996       5  we enjoyed lillie s teppanyaki or as they call...   test\n",
       "64997       5  we just purchased a vehicle from centennial la...   test\n",
       "64998       5  they make great vegetarian thai food they do t...   test\n",
       "64999       5  it s a must to stop at trader joes while in ve...   test\n",
       "\n",
       "[65000 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27eb5b",
   "metadata": {},
   "source": [
    "## Pytorch Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dad1ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "398c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
    "        \"\"\"\n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.review_df[self.review_df.split=='val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                            'val': (self.val_df, self.val_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\" Load dataset and make a new vectorizer form scratch\n",
    "        \n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "        Returns: \n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(review_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" Returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point\n",
    "        Returns:\n",
    "            a dict of the data point's features (x_data) and label (y_target)\n",
    "        \n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        review_vector = \\\n",
    "        self._vectorizer.vectorize(row.review)\n",
    "        \n",
    "        rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "        \n",
    "        return {'x_data': review_vector,\n",
    "               'y_target': rating_index}\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\" Given a batch size, return the number of batches in the dataset\"\"\"\n",
    "        return len(self) // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\" Class to proces text and extract Vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the vocabulary\n",
    "        \"\"\"\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            toke_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        \n",
    "        self._idx_to_token = {idx: token for token, idx in sel._token_to_idx.items{}}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "            \n",
    "        def to_serializable(self):\n",
    "            \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "            return {'token_to_idx': self._token_to_idx,\n",
    "                   'add_unk': self._add_unk,\n",
    "                   'unk_token': self._unk_token}\n",
    "        \n",
    "        @classmethod\n",
    "        def from_serializable(cls, contents):\n",
    "            \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "            return cls(**contents)\n",
    "        \n",
    "        def add_token(self, token):\n",
    "            \"\"\" Update mapping dicts based on the token. \n",
    "                Args:\n",
    "                    token (str): the item to add into the Vocabulary\n",
    "                Returns:\n",
    "                    index (int): the integer correspoiding to the token\n",
    "                \"\"\"\n",
    "            if token in seld._token_to_idx:\n",
    "                index = self._token_to_idx[token]\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
